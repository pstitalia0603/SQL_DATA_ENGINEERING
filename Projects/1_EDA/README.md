# ðŸ” Exploratory Data Analysis w/ SQL: Job Market Analytics

![EDA Project Overview](images/1_1_Project1_EDA.png)

A SQL project analyzing the data engineer job market using real world job posting data. It demonstrates my ability to **write production-quality analytical SQL, design efficient queries, and turn business questions into data-driven insights**.

---

## ðŸ§¾ Executive Summary (For Hiring Managers)

- âœ… **Project scope:** Built **3 analytical queries** that answer key questions about the data engineer job market
- âœ… **Data modeling:** Used **multi-table joins** across fact and dimension tables to extract insights
- âœ… **Analytics:** Applied **aggregations, filtering, and sorting** to find top skills by demand, salary, and overall value
- âœ… **Outcomes:** Delivered **actionable insights** on SQL/Python dominance, cloud trends, and salary patterns

If you only have a minute, review these:

1. [`01_top_demanded_skills.sql`](./01_top_demanded_skills.sql) â€“ demand analysis with multi-table joins
2. [`02_top_paying_skills.sql`](./02_top_paying_skills.sql) â€“ salary analysis with aggregations
3. [`03_optimal_skills.sql`](./03_optimal_skills.sql) â€“ combined demand/salary optimization query

---

## ðŸ§© Problem & Context

Job market analysts need to answer questions like:

- ðŸŽ¯ **Most in-demand:** _Which skills are most in-demand for data engineers?_
- ðŸ’° **Highest paid:** _Which skills command the highest salaries?_
- âš–ï¸ **Best trade-off:** _What is the optimal skill set balancing demand and compensation?_

This project analyzes a **data warehouse** built using a star schema design. The warehouse structure consists of:

![Data Warehouse Schema](images/1_2_Data_Warehouse.png)

- **Fact Table:** `job_postings_fact` - Central table containing job posting details (job titles, locations, salaries, dates, etc.)
- **Dimension Tables:**
  - `company_dim` - Company information linked to job postings
  - `skills_dim` - Skills catalog with skill names and types
- **Bridge Table:** `skills_job_dim` - Resolves the many-to-many relationship between job postings and skills

By querying across these interconnected tables, I extracted insights about skill demand, salary patterns, and optimal skill combinations for data engineering roles.

---

## ðŸ§° Tech Stack

- ðŸ¤ **Query Engine:** DuckDB for fast OLAP-style analytical queries
- ðŸ§® **Language:** SQL (ANSI-style with analytical functions)
- ðŸ“Š **Data Model:** Star schema with fact + dimension + bridge tables
- ðŸ› ï¸ **Development:** VS Code for SQL editing + Terminal for DuckDB CLI
- ðŸ“¦ **Version Control:** Git/GitHub for versioned SQL scripts

---

## ðŸ“‚ Repository Structure

```text
1_EDA/
â”œâ”€â”€ 01_top_demanded_skills.sql    # Demand analysis query
â”œâ”€â”€ 02_top_paying_skills.sql      # Salary analysis query
â”œâ”€â”€ 03_optimal_skills.sql         # Combined demand/salary optimization
â””â”€â”€ README.md                     # You are here
```

---

## ðŸ— Analysis Overview

### Query Structure

1. **[Top Demanded Skills](./01_top_demanded_skills.sql)** â€“ Identifies the 10 most in-demand skills for remote data engineer positions
2. **[Top Paying Skills](./02_top_paying_skills.sql)** â€“ Analyzes the 25 highest-paying skills with salary and demand metrics
3. **[Optimal Skills](./03_optimal_skills.sql)** â€“ Calculates an optimal score using natural log of demand combined with median salary to identify the most valuable skills to learn

### Key Insights

- ðŸ§  Core languages: SQL and Python each appear in ~29,000 job postings, making them the most demanded skills
- â˜ï¸ Cloud platforms: AWS and Azure are critical for modern data engineering roles-
- ðŸ§± Infra & tooling: Kubernetes, Docker, and Terraform are associated with premium salaries
- ðŸ”¥ Big data tools: Apache Spark shows strong demand with competitive compensation

---

## ðŸ’» SQL Skills Demonstrated

### Query Design & Optimization

- **Complex Joins**: Multi-table `INNER JOIN` operations across `job_postings_fact`, `skills_job_dim`, and `skills_dim`
- **Aggregations**: `COUNT()`, `MEDIAN()`, `ROUND()` for statistical analysis
- **Filtering**: Boolean logic with `WHERE` clauses and multiple conditions (`job_title_short`, `job_work_from_home`, `salary_year_avg IS NOT NULL`)
- **Sorting & Limiting**: `ORDER BY` with `DESC` and `LIMIT` for top-N analysis

### Data Analysis Techniques

- **Grouping**: `GROUP BY` for categorical analysis by skill
- **Mathematical Functions**: `LN()` for natural logarithm transformation to normalize demand metrics
- **Calculated Metrics**: Derived optimal score combining log-transformed demand with median salary
- **HAVING Clause**: Filtering aggregated results (skills with >= 100 postings)
- **NULL Handling**: Proper filtering of incomplete records (`salary_year_avg IS NOT NULL`)
